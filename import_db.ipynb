{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import sqlalchemy as sqla\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"postgres\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "SQL_INIT = \"init.sql\"\n",
    "\n",
    "engine = sqla.create_engine(f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database initialized\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(SQL_INIT, \"r\") as f:\n",
    "        query = f.read()\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(sqla.text(query))\n",
    "        print(\"Database initialized\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION loaded\n"
     ]
    }
   ],
   "source": [
    "REGION_FILE = \"REGION.csv\"\n",
    "\n",
    "try:\n",
    "    conn = engine.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with(open(REGION_FILE, \"r\")) as f:\n",
    "        cursor.copy_expert(\n",
    "        \"\"\"\n",
    "            COPY region FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "        \"\"\",f)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(\"REGION loaded\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service loaded\n"
     ]
    }
   ],
   "source": [
    "SERVICE_FILE = \"TRAIN_SERV.csv\"\n",
    "\n",
    "try:\n",
    "    conn = engine.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with(open(SERVICE_FILE, \"r\")) as f:\n",
    "        cursor.copy_expert(\n",
    "        \"\"\"\n",
    "            COPY service FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "        \"\"\",f)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(\"Service loaded\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations loaded\n"
     ]
    }
   ],
   "source": [
    "STATIONS_FILE = \"better_station.csv\"\n",
    "try:\n",
    "    conn = engine.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with(open(STATIONS_FILE, \"r\")) as f:\n",
    "        cursor.copy_expert(\n",
    "        \"\"\"\n",
    "            COPY stations FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "        \"\"\",f)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(\"Stations loaded\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELATION loaded\n"
     ]
    }
   ],
   "source": [
    "RELATION_FILE = \"RELATION.csv\"\n",
    "\n",
    "try:\n",
    "    conn = engine.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with(open(RELATION_FILE, \"r\")) as f:\n",
    "        cursor.copy_expert(\n",
    "        \"\"\"\n",
    "            COPY relation FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "        \"\"\",f)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(\"RELATION loaded\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_raw_punctuality_201401.csv loaded\n",
      "Data_raw_punctuality_201402.csv loaded\n",
      "Data_raw_punctuality_201403.csv loaded\n",
      "Data_raw_punctuality_201404.csv loaded\n",
      "Data_raw_punctuality_201405.csv loaded\n",
      "Data_raw_punctuality_201406.csv loaded\n",
      "Data_raw_punctuality_201407.csv loaded\n",
      "Data_raw_punctuality_201408.csv loaded\n",
      "Data_raw_punctuality_201409.csv loaded\n",
      "Data_raw_punctuality_201410.csv loaded\n",
      "Data_raw_punctuality_201411.csv loaded\n",
      "Data_raw_punctuality_201412.csv loaded\n",
      "Data_raw_punctuality_201501.csv loaded\n",
      "Data_raw_punctuality_201502.csv loaded\n",
      "Data_raw_punctuality_201503.csv loaded\n",
      "Data_raw_punctuality_201504.csv loaded\n",
      "Data_raw_punctuality_201505.csv loaded\n",
      "Data_raw_punctuality_201506.csv loaded\n",
      "Data_raw_punctuality_201507.csv loaded\n",
      "Data_raw_punctuality_201508.csv loaded\n",
      "Data_raw_punctuality_201509.csv loaded\n",
      "Data_raw_punctuality_201510.csv loaded\n",
      "Data_raw_punctuality_201511.csv loaded\n",
      "Data_raw_punctuality_201512.csv loaded\n",
      "Data_raw_punctuality_201601.csv loaded\n",
      "Data_raw_punctuality_201602.csv loaded\n",
      "Data_raw_punctuality_201603.csv loaded\n",
      "Data_raw_punctuality_201604.csv loaded\n",
      "Data_raw_punctuality_201605.csv loaded\n",
      "Data_raw_punctuality_201606.csv loaded\n",
      "Data_raw_punctuality_201607.csv loaded\n",
      "Data_raw_punctuality_201608.csv loaded\n",
      "Data_raw_punctuality_201609.csv loaded\n",
      "Data_raw_punctuality_201610.csv loaded\n",
      "Data_raw_punctuality_201611.csv loaded\n",
      "Data_raw_punctuality_201612.csv loaded\n",
      "Data_raw_punctuality_201701.csv loaded\n",
      "Data_raw_punctuality_201702.csv loaded\n",
      "Data_raw_punctuality_201703.csv loaded\n",
      "Data_raw_punctuality_201704.csv loaded\n",
      "Data_raw_punctuality_201705.csv loaded\n",
      "Data_raw_punctuality_201706.csv loaded\n",
      "Data_raw_punctuality_201707.csv loaded\n",
      "Data_raw_punctuality_201708.csv loaded\n",
      "Data_raw_punctuality_201709.csv loaded\n",
      "Data_raw_punctuality_201710.csv loaded\n",
      "Data_raw_punctuality_201711.csv loaded\n",
      "Data_raw_punctuality_201712.csv loaded\n",
      "Data_raw_punctuality_201801.csv loaded\n",
      "Data_raw_punctuality_201802.csv loaded\n",
      "Data_raw_punctuality_201803.csv loaded\n",
      "Data_raw_punctuality_201804.csv loaded\n",
      "Data_raw_punctuality_201805.csv loaded\n",
      "Data_raw_punctuality_201806.csv loaded\n",
      "Data_raw_punctuality_201807.csv loaded\n",
      "Data_raw_punctuality_201808.csv loaded\n",
      "Data_raw_punctuality_201809.csv loaded\n",
      "Data_raw_punctuality_201810.csv loaded\n",
      "Data_raw_punctuality_201811.csv loaded\n",
      "Data_raw_punctuality_201812.csv loaded\n",
      "Data_raw_punctuality_201901.csv loaded\n",
      "Data_raw_punctuality_201902.csv loaded\n",
      "Data_raw_punctuality_201903.csv loaded\n",
      "Data_raw_punctuality_201904.csv loaded\n",
      "Data_raw_punctuality_201905.csv loaded\n",
      "Data_raw_punctuality_201906.csv loaded\n",
      "Data_raw_punctuality_201907.csv loaded\n",
      "Data_raw_punctuality_201908.csv loaded\n",
      "Data_raw_punctuality_201909.csv loaded\n",
      "Data_raw_punctuality_201910.csv loaded\n",
      "Data_raw_punctuality_201911.csv loaded\n",
      "Data_raw_punctuality_201912.csv loaded\n",
      "Data_raw_punctuality_202001.csv loaded\n",
      "Data_raw_punctuality_202002.csv loaded\n",
      "Data_raw_punctuality_202003.csv loaded\n",
      "Data_raw_punctuality_202004.csv loaded\n",
      "Data_raw_punctuality_202005.csv loaded\n",
      "Data_raw_punctuality_202006.csv loaded\n",
      "Data_raw_punctuality_202007.csv loaded\n",
      "Data_raw_punctuality_202008.csv loaded\n",
      "Data_raw_punctuality_202009.csv loaded\n",
      "Data_raw_punctuality_202010.csv loaded\n",
      "Data_raw_punctuality_202011.csv loaded\n",
      "Data_raw_punctuality_202012.csv loaded\n",
      "Data_raw_punctuality_202101.csv loaded\n",
      "Data_raw_punctuality_202102.csv loaded\n",
      "Data_raw_punctuality_202103.csv loaded\n",
      "Data_raw_punctuality_202104.csv loaded\n",
      "Data_raw_punctuality_202105.csv loaded\n",
      "Data_raw_punctuality_202106.csv loaded\n",
      "Data_raw_punctuality_202107.csv loaded\n",
      "Data_raw_punctuality_202108.csv loaded\n",
      "Data_raw_punctuality_202109.csv loaded\n",
      "Data_raw_punctuality_202110.csv loaded\n",
      "Data_raw_punctuality_202111.csv loaded\n",
      "Data_raw_punctuality_202112.csv loaded\n",
      "Data_raw_punctuality_202201.csv loaded\n",
      "Data_raw_punctuality_202202.csv loaded\n",
      "Data_raw_punctuality_202203.csv loaded\n",
      "Data_raw_punctuality_202204.csv loaded\n",
      "Data_raw_punctuality_202205.csv loaded\n",
      "Data_raw_punctuality_202206.csv loaded\n",
      "Data_raw_punctuality_202207.csv loaded\n",
      "Data_raw_punctuality_202208.csv loaded\n",
      "Data_raw_punctuality_202209.csv loaded\n",
      "Data_raw_punctuality_202210.csv loaded\n",
      "Data_raw_punctuality_202211.csv loaded\n",
      "Data_raw_punctuality_202212.csv loaded\n",
      "Data_raw_punctuality_202301.csv loaded\n",
      "Data_raw_punctuality_202302.csv loaded\n",
      "Data_raw_punctuality_202303.csv loaded\n",
      "Data_raw_punctuality_202304.csv loaded\n",
      "Data_raw_punctuality_202305.csv loaded\n",
      "Data_raw_punctuality_202306.csv loaded\n",
      "Data_raw_punctuality_202307.csv loaded\n",
      "Data_raw_punctuality_202308.csv loaded\n",
      "Data_raw_punctuality_202309.csv loaded\n",
      "Data_raw_punctuality_202310.csv loaded\n",
      "Data_raw_punctuality_202311.csv loaded\n",
      "Data_raw_punctuality_202312.csv loaded\n",
      "Data_raw_punctuality_202401.csv loaded\n",
      "Data_raw_punctuality_202402.csv loaded\n",
      "Data_raw_punctuality_202403.csv loaded\n",
      "Data_raw_punctuality_202404.csv loaded\n",
      "Data_raw_punctuality_202405.csv loaded\n",
      "Data_raw_punctuality_202406.csv loaded\n",
      "Data_raw_punctuality_202407.csv loaded\n",
      "Data_raw_punctuality_202408.csv loaded\n",
      "Data_raw_punctuality_202409.csv loaded\n",
      "Data_raw_punctuality_202410.csv loaded\n",
      "Data_raw_punctuality_202411.csv loaded\n",
      "Data_raw_punctuality_202412.csv loaded\n"
     ]
    }
   ],
   "source": [
    "# We now load the datasets into the database\n",
    "DATASET_DIR = \"cleaned_dataset\"\n",
    "DATASET_FILES = os.listdir(DATASET_DIR)\n",
    "\n",
    "for file in DATASET_FILES:\n",
    "    try:\n",
    "        conn = engine.raw_connection()\n",
    "        cursor = conn.cursor()\n",
    "        with(open(f\"{DATASET_DIR}/{file}\", \"r\")) as f:\n",
    "            cursor.copy_expert(\n",
    "            \"\"\"\n",
    "                COPY train_data FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "            \"\"\",f)\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        print(f\"{file} loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather loaded\n"
     ]
    }
   ],
   "source": [
    "WEATHER_FILE = \"belgium_hourly_weather_2014_2024.csv\"\n",
    "\n",
    "try:\n",
    "    conn = engine.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    with(open(WEATHER_FILE, \"r\")) as f:\n",
    "        cursor.copy_expert(\n",
    "        \"\"\"\n",
    "            COPY weather FROM STDIN WITH CSV HEADER DELIMITER ',' NULL ''\n",
    "        \"\"\",f)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print(\"weather loaded\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
