{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sqla\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATABASE CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL successfully!\n"
     ]
    }
   ],
   "source": [
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"a\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"postgres\"\n",
    "\n",
    "connection_string = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "# Cr√©er un moteur SQLAlchemy\n",
    "engine = sqla.create_engine(connection_string)\n",
    "\n",
    "# Tester la connexion\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connected to PostgreSQL successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90390, 16)\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "w.date,\n",
    "EXTRACT(HOUR FROM w.hour) AS hour_of_day,\n",
    "AVG(w.temperature) AS avg_temperature,\n",
    "AVG(w.dewpoint) AS avg_dewpoint,\n",
    "AVG(w.relative_humidity) AS avg_relative_humidity,\n",
    "AVG(w.precipitation) AS avg_precipitation,\n",
    "AVG(w.snowfall) AS avg_snowfall,\n",
    "AVG(w.wind_direction) AS avg_wind_direction,\n",
    "AVG(w.wind_speed) AS avg_wind_speed,\n",
    "AVG(w.pressure) AS avg_pressure\n",
    "FROM WEATHER w\n",
    "GROUP BY w.date, hour_of_day\n",
    "ORDER BY w.date, hour_of_day;\n",
    "\"\"\"\n",
    "\n",
    "weather = pd.read_sql(sqla.text(query), connection)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        t.departure_date AS date,\n",
    "        EXTRACT(HOUR FROM t.real_time_departure) AS hour_of_day,\n",
    "        AVG(t.delay_arrival) AS avg_delay_arrival,\n",
    "        AVG(t.delay_departure) AS avg_delay_departure\n",
    "    FROM TRAIN_DATA t\n",
    "    GROUP BY t.departure_date, hour_of_day\n",
    "    ORDER BY t.departure_date, hour_of_day;\n",
    "\"\"\"\n",
    "\n",
    "train_data = pd.read_sql(sqla.text(query), connection)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * FROM TYPE_DAY;\n",
    "\"\"\"\n",
    "\n",
    "type_day = pd.read_sql(sqla.text(query), connection)\n",
    "\n",
    "\n",
    "merged_df = train_data.merge(weather, on=[\"date\", \"hour_of_day\"], how=\"inner\")\n",
    "\n",
    "merged_df = type_day.merge(merged_df, on=[\"date\"], how=\"inner\")\n",
    "\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "\n",
    "merged_df['date'] = merged_df['date'].dt.dayofyear\n",
    "\n",
    "merged_df['day_sin'] = np.sin(2 * np.pi * merged_df['date'] / 365)\n",
    "merged_df['day_cos'] = np.cos(2 * np.pi * merged_df['date'] / 365)\n",
    "\n",
    "# Drop the original 'date' column\n",
    "merged_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier,StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression,RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_train(xtrain,xtest,ytrain,ytest,model, print_results=True):\n",
    "    model.fit(xtrain,ytrain)\n",
    "    ypred = model.predict(xtest)\n",
    "    print(\"Model\",model)\n",
    "    print(\"Accuracy\",accuracy_score(ytest,ypred))\n",
    "    if print_results:\n",
    "        print(\"Confusion Matrix\\n\",confusion_matrix(ytest,ypred))\n",
    "        print(\"Classification Report\\n\",classification_report(ytest,ypred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only the weather dummy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.14999774464917\n",
      "Model KNeighborsClassifier()\n",
      "Accuracy 0.5769443522513552\n",
      "Confusion Matrix\n",
      " [[5237 3801]\n",
      " [3847 5193]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58      9038\n",
      "           1       0.58      0.57      0.58      9040\n",
      "\n",
      "    accuracy                           0.58     18078\n",
      "   macro avg       0.58      0.58      0.58     18078\n",
      "weighted avg       0.58      0.58      0.58     18078\n",
      "\n",
      "Model DecisionTreeClassifier()\n",
      "Accuracy 0.5809270937050559\n",
      "Confusion Matrix\n",
      " [[5302 3736]\n",
      " [3840 5200]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.59      0.58      9038\n",
      "           1       0.58      0.58      0.58      9040\n",
      "\n",
      "    accuracy                           0.58     18078\n",
      "   macro avg       0.58      0.58      0.58     18078\n",
      "weighted avg       0.58      0.58      0.58     18078\n",
      "\n",
      "Model RandomForestClassifier()\n",
      "Accuracy 0.6426595862374156\n",
      "Confusion Matrix\n",
      " [[6032 3006]\n",
      " [3454 5586]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65      9038\n",
      "           1       0.65      0.62      0.63      9040\n",
      "\n",
      "    accuracy                           0.64     18078\n",
      "   macro avg       0.64      0.64      0.64     18078\n",
      "weighted avg       0.64      0.64      0.64     18078\n",
      "\n",
      "Model AdaBoostClassifier()\n",
      "Accuracy 0.5297599291957075\n",
      "Confusion Matrix\n",
      " [[5180 3858]\n",
      " [4643 4397]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.57      0.55      9038\n",
      "           1       0.53      0.49      0.51      9040\n",
      "\n",
      "    accuracy                           0.53     18078\n",
      "   macro avg       0.53      0.53      0.53     18078\n",
      "weighted avg       0.53      0.53      0.53     18078\n",
      "\n",
      "Model GradientBoostingClassifier()\n",
      "Accuracy 0.5443633145259431\n",
      "Confusion Matrix\n",
      " [[5379 3659]\n",
      " [4578 4462]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.60      0.57      9038\n",
      "           1       0.55      0.49      0.52      9040\n",
      "\n",
      "    accuracy                           0.54     18078\n",
      "   macro avg       0.54      0.54      0.54     18078\n",
      "weighted avg       0.54      0.54      0.54     18078\n",
      "\n",
      "Model ExtraTreesClassifier()\n",
      "Accuracy 0.6552716008408009\n",
      "Confusion Matrix\n",
      " [[6105 2933]\n",
      " [3299 5741]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      9038\n",
      "           1       0.66      0.64      0.65      9040\n",
      "\n",
      "    accuracy                           0.66     18078\n",
      "   macro avg       0.66      0.66      0.66     18078\n",
      "weighted avg       0.66      0.66      0.66     18078\n",
      "\n",
      "Model BaggingClassifier()\n",
      "Accuracy 0.6036619095032636\n",
      "Confusion Matrix\n",
      " [[6234 2804]\n",
      " [4361 4679]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.69      0.64      9038\n",
      "           1       0.63      0.52      0.57      9040\n",
      "\n",
      "    accuracy                           0.60     18078\n",
      "   macro avg       0.61      0.60      0.60     18078\n",
      "weighted avg       0.61      0.60      0.60     18078\n",
      "\n",
      "Model GaussianNB()\n",
      "Accuracy 0.5050890585241731\n",
      "Confusion Matrix\n",
      " [[8844  194]\n",
      " [8753  287]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66      9038\n",
      "           1       0.60      0.03      0.06      9040\n",
      "\n",
      "    accuracy                           0.51     18078\n",
      "   macro avg       0.55      0.51      0.36     18078\n",
      "weighted avg       0.55      0.51      0.36     18078\n",
      "\n",
      "Model SGDClassifier()\n",
      "Accuracy 0.5031530036508464\n",
      "Confusion Matrix\n",
      " [[8943   95]\n",
      " [8887  153]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.99      0.67      9038\n",
      "           1       0.62      0.02      0.03      9040\n",
      "\n",
      "    accuracy                           0.50     18078\n",
      "   macro avg       0.56      0.50      0.35     18078\n",
      "weighted avg       0.56      0.50      0.35     18078\n",
      "\n",
      "Model LogisticRegression()\n",
      "Accuracy 0.5174798097134639\n",
      "Confusion Matrix\n",
      " [[5539 3499]\n",
      " [5224 3816]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.61      0.56      9038\n",
      "           1       0.52      0.42      0.47      9040\n",
      "\n",
      "    accuracy                           0.52     18078\n",
      "   macro avg       0.52      0.52      0.51     18078\n",
      "weighted avg       0.52      0.52      0.51     18078\n",
      "\n",
      "Model RidgeClassifier()\n",
      "Accuracy 0.5179223365416529\n",
      "Confusion Matrix\n",
      " [[5190 3848]\n",
      " [4867 4173]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.54      9038\n",
      "           1       0.52      0.46      0.49      9040\n",
      "\n",
      "    accuracy                           0.52     18078\n",
      "   macro avg       0.52      0.52      0.52     18078\n",
      "weighted avg       0.52      0.52      0.52     18078\n",
      "\n",
      "Model SVC()\n",
      "Accuracy 0.5105653280230114\n",
      "Confusion Matrix\n",
      " [[6602 2436]\n",
      " [6412 2628]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.73      0.60      9038\n",
      "           1       0.52      0.29      0.37      9040\n",
      "\n",
      "    accuracy                           0.51     18078\n",
      "   macro avg       0.51      0.51      0.49     18078\n",
      "weighted avg       0.51      0.51      0.49     18078\n",
      "\n",
      "Model MLPClassifier()\n",
      "Accuracy 0.5000553158535236\n",
      "Confusion Matrix\n",
      " [[   0 9038]\n",
      " [   0 9040]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      9038\n",
      "           1       0.50      1.00      0.67      9040\n",
      "\n",
      "    accuracy                           0.50     18078\n",
      "   macro avg       0.25      0.50      0.33     18078\n",
      "weighted avg       0.25      0.50      0.33     18078\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leiya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leiya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\leiya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "x = merged_df[[\"avg_temperature\", \"avg_dewpoint\", \"avg_relative_humidity\", \"avg_precipitation\", \"avg_snowfall\", \"avg_wind_direction\", \"avg_wind_speed\", \"avg_pressure\"]]\n",
    "y = merged_df[\"avg_delay_departure\"]\n",
    "\n",
    "median_y = y.median()\n",
    "print(median_y)\n",
    "\n",
    "new_y = y.apply(lambda x: 1 if x > median_y else 0)\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,new_y,test_size=0.2,random_state=42)\n",
    "\n",
    "models = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier(),BaggingClassifier(),GaussianNB(),SGDClassifier(),LogisticRegression(),RidgeClassifier(),SVC(),MLPClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    dummy_train(xtrain,xtest,ytrain,ytest,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only using the hours and date dummies test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.14999774464917\n",
      "Model KNeighborsClassifier()\n",
      "Accuracy 0.6945458568425711\n",
      "Confusion Matrix\n",
      " [[6156 2882]\n",
      " [2640 6400]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      9038\n",
      "           1       0.69      0.71      0.70      9040\n",
      "\n",
      "    accuracy                           0.69     18078\n",
      "   macro avg       0.69      0.69      0.69     18078\n",
      "weighted avg       0.69      0.69      0.69     18078\n",
      "\n",
      "Model DecisionTreeClassifier()\n",
      "Accuracy 0.6677729837371391\n",
      "Confusion Matrix\n",
      " [[6543 2495]\n",
      " [3511 5529]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.69      9038\n",
      "           1       0.69      0.61      0.65      9040\n",
      "\n",
      "    accuracy                           0.67     18078\n",
      "   macro avg       0.67      0.67      0.67     18078\n",
      "weighted avg       0.67      0.67      0.67     18078\n",
      "\n",
      "Model RandomForestClassifier()\n",
      "Accuracy 0.686856953202788\n",
      "Confusion Matrix\n",
      " [[6166 2872]\n",
      " [2789 6251]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.69      9038\n",
      "           1       0.69      0.69      0.69      9040\n",
      "\n",
      "    accuracy                           0.69     18078\n",
      "   macro avg       0.69      0.69      0.69     18078\n",
      "weighted avg       0.69      0.69      0.69     18078\n",
      "\n",
      "Model AdaBoostClassifier()\n",
      "Accuracy 0.6970903861046576\n",
      "Confusion Matrix\n",
      " [[5653 3385]\n",
      " [2091 6949]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.67      9038\n",
      "           1       0.67      0.77      0.72      9040\n",
      "\n",
      "    accuracy                           0.70     18078\n",
      "   macro avg       0.70      0.70      0.70     18078\n",
      "weighted avg       0.70      0.70      0.70     18078\n",
      "\n",
      "Model GradientBoostingClassifier()\n",
      "Accuracy 0.7223144153114283\n",
      "Confusion Matrix\n",
      " [[6112 2926]\n",
      " [2094 6946]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      9038\n",
      "           1       0.70      0.77      0.73      9040\n",
      "\n",
      "    accuracy                           0.72     18078\n",
      "   macro avg       0.72      0.72      0.72     18078\n",
      "weighted avg       0.72      0.72      0.72     18078\n",
      "\n",
      "Model ExtraTreesClassifier()\n",
      "Accuracy 0.676070361765682\n",
      "Confusion Matrix\n",
      " [[6568 2470]\n",
      " [3386 5654]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69      9038\n",
      "           1       0.70      0.63      0.66      9040\n",
      "\n",
      "    accuracy                           0.68     18078\n",
      "   macro avg       0.68      0.68      0.68     18078\n",
      "weighted avg       0.68      0.68      0.68     18078\n",
      "\n",
      "Model BaggingClassifier()\n",
      "Accuracy 0.6798318398052882\n",
      "Confusion Matrix\n",
      " [[6113 2925]\n",
      " [2863 6177]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      9038\n",
      "           1       0.68      0.68      0.68      9040\n",
      "\n",
      "    accuracy                           0.68     18078\n",
      "   macro avg       0.68      0.68      0.68     18078\n",
      "weighted avg       0.68      0.68      0.68     18078\n",
      "\n",
      "Model GaussianNB()\n",
      "Accuracy 0.5927646863591105\n",
      "Confusion Matrix\n",
      " [[5605 3433]\n",
      " [3929 5111]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.60      9038\n",
      "           1       0.60      0.57      0.58      9040\n",
      "\n",
      "    accuracy                           0.59     18078\n",
      "   macro avg       0.59      0.59      0.59     18078\n",
      "weighted avg       0.59      0.59      0.59     18078\n",
      "\n",
      "Model SGDClassifier()\n",
      "Accuracy 0.5543754840137183\n",
      "Confusion Matrix\n",
      " [[2477 6561]\n",
      " [1495 7545]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.27      0.38      9038\n",
      "           1       0.53      0.83      0.65      9040\n",
      "\n",
      "    accuracy                           0.55     18078\n",
      "   macro avg       0.58      0.55      0.52     18078\n",
      "weighted avg       0.58      0.55      0.52     18078\n",
      "\n",
      "Model LogisticRegression()\n",
      "Accuracy 0.6006748534129882\n",
      "Confusion Matrix\n",
      " [[5130 3908]\n",
      " [3311 5729]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59      9038\n",
      "           1       0.59      0.63      0.61      9040\n",
      "\n",
      "    accuracy                           0.60     18078\n",
      "   macro avg       0.60      0.60      0.60     18078\n",
      "weighted avg       0.60      0.60      0.60     18078\n",
      "\n",
      "Model RidgeClassifier()\n",
      "Accuracy 0.6002876424383228\n",
      "Confusion Matrix\n",
      " [[5089 3949]\n",
      " [3277 5763]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.58      9038\n",
      "           1       0.59      0.64      0.61      9040\n",
      "\n",
      "    accuracy                           0.60     18078\n",
      "   macro avg       0.60      0.60      0.60     18078\n",
      "weighted avg       0.60      0.60      0.60     18078\n",
      "\n",
      "Model SVC()\n",
      "Accuracy 0.6520079654829074\n",
      "Confusion Matrix\n",
      " [[5003 4035]\n",
      " [2256 6784]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61      9038\n",
      "           1       0.63      0.75      0.68      9040\n",
      "\n",
      "    accuracy                           0.65     18078\n",
      "   macro avg       0.66      0.65      0.65     18078\n",
      "weighted avg       0.66      0.65      0.65     18078\n",
      "\n",
      "Model MLPClassifier()\n",
      "Accuracy 0.714348932404027\n",
      "Confusion Matrix\n",
      " [[5462 3576]\n",
      " [1588 7452]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.60      0.68      9038\n",
      "           1       0.68      0.82      0.74      9040\n",
      "\n",
      "    accuracy                           0.71     18078\n",
      "   macro avg       0.73      0.71      0.71     18078\n",
      "weighted avg       0.73      0.71      0.71     18078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = merged_df[[\"day_sin\",\"day_cos\",\"holiday\",\"weekend\", \"day_after_rest\",\"hour_of_day\"]]\n",
    "y = merged_df[\"avg_delay_departure\"]\n",
    "\n",
    "median_y = y.median()\n",
    "print(median_y)\n",
    "\n",
    "new_y = y.apply(lambda x: 1 if x > median_y else 0)\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,new_y,test_size=0.2,random_state=42)\n",
    "\n",
    "models = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier(),BaggingClassifier(),GaussianNB(),SGDClassifier(),LogisticRegression(),RidgeClassifier(),SVC(),MLPClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    dummy_train(xtrain,xtest,ytrain,ytest,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model KNeighborsClassifier()\n",
      "Accuracy 0.6443190618431243\n",
      "Confusion Matrix\n",
      " [[5946 3092]\n",
      " [3338 5702]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      9038\n",
      "           1       0.65      0.63      0.64      9040\n",
      "\n",
      "    accuracy                           0.64     18078\n",
      "   macro avg       0.64      0.64      0.64     18078\n",
      "weighted avg       0.64      0.64      0.64     18078\n",
      "\n",
      "Model DecisionTreeClassifier()\n",
      "Accuracy 0.7282332116384556\n",
      "Confusion Matrix\n",
      " [[6605 2433]\n",
      " [2480 6560]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73      9038\n",
      "           1       0.73      0.73      0.73      9040\n",
      "\n",
      "    accuracy                           0.73     18078\n",
      "   macro avg       0.73      0.73      0.73     18078\n",
      "weighted avg       0.73      0.73      0.73     18078\n",
      "\n",
      "Model RandomForestClassifier()\n",
      "Accuracy 0.8243168492089833\n",
      "Confusion Matrix\n",
      " [[7355 1683]\n",
      " [1493 7547]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      9038\n",
      "           1       0.82      0.83      0.83      9040\n",
      "\n",
      "    accuracy                           0.82     18078\n",
      "   macro avg       0.82      0.82      0.82     18078\n",
      "weighted avg       0.82      0.82      0.82     18078\n",
      "\n",
      "Model AdaBoostClassifier()\n",
      "Accuracy 0.7036176568204447\n",
      "Confusion Matrix\n",
      " [[5702 3336]\n",
      " [2022 7018]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68      9038\n",
      "           1       0.68      0.78      0.72      9040\n",
      "\n",
      "    accuracy                           0.70     18078\n",
      "   macro avg       0.71      0.70      0.70     18078\n",
      "weighted avg       0.71      0.70      0.70     18078\n",
      "\n",
      "Model GradientBoostingClassifier()\n",
      "Accuracy 0.7357561677176678\n",
      "Confusion Matrix\n",
      " [[6205 2833]\n",
      " [1944 7096]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72      9038\n",
      "           1       0.71      0.78      0.75      9040\n",
      "\n",
      "    accuracy                           0.74     18078\n",
      "   macro avg       0.74      0.74      0.74     18078\n",
      "weighted avg       0.74      0.74      0.74     18078\n",
      "\n",
      "Model ExtraTreesClassifier()\n",
      "Accuracy 0.8291293284655382\n",
      "Confusion Matrix\n",
      " [[7487 1551]\n",
      " [1538 7502]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      9038\n",
      "           1       0.83      0.83      0.83      9040\n",
      "\n",
      "    accuracy                           0.83     18078\n",
      "   macro avg       0.83      0.83      0.83     18078\n",
      "weighted avg       0.83      0.83      0.83     18078\n",
      "\n",
      "Model BaggingClassifier()\n",
      "Accuracy 0.7781834273702843\n",
      "Confusion Matrix\n",
      " [[7249 1789]\n",
      " [2221 6819]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      9038\n",
      "           1       0.79      0.75      0.77      9040\n",
      "\n",
      "    accuracy                           0.78     18078\n",
      "   macro avg       0.78      0.78      0.78     18078\n",
      "weighted avg       0.78      0.78      0.78     18078\n",
      "\n",
      "Model GaussianNB()\n",
      "Accuracy 0.5231220267728731\n",
      "Confusion Matrix\n",
      " [[8152  886]\n",
      " [7735 1305]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65      9038\n",
      "           1       0.60      0.14      0.23      9040\n",
      "\n",
      "    accuracy                           0.52     18078\n",
      "   macro avg       0.55      0.52      0.44     18078\n",
      "weighted avg       0.55      0.52      0.44     18078\n",
      "\n",
      "Model SGDClassifier()\n",
      "Accuracy 0.5774975107865914\n",
      "Confusion Matrix\n",
      " [[2706 6332]\n",
      " [1306 7734]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.30      0.41      9038\n",
      "           1       0.55      0.86      0.67      9040\n",
      "\n",
      "    accuracy                           0.58     18078\n",
      "   macro avg       0.61      0.58      0.54     18078\n",
      "weighted avg       0.61      0.58      0.54     18078\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leiya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogisticRegression()\n",
      "Accuracy 0.6046575948666888\n",
      "Confusion Matrix\n",
      " [[5242 3796]\n",
      " [3351 5689]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59      9038\n",
      "           1       0.60      0.63      0.61      9040\n",
      "\n",
      "    accuracy                           0.60     18078\n",
      "   macro avg       0.60      0.60      0.60     18078\n",
      "weighted avg       0.60      0.60      0.60     18078\n",
      "\n",
      "Model RidgeClassifier()\n",
      "Accuracy 0.6046022790131652\n",
      "Confusion Matrix\n",
      " [[5178 3860]\n",
      " [3288 5752]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59      9038\n",
      "           1       0.60      0.64      0.62      9040\n",
      "\n",
      "    accuracy                           0.60     18078\n",
      "   macro avg       0.61      0.60      0.60     18078\n",
      "weighted avg       0.61      0.60      0.60     18078\n",
      "\n",
      "Model SVC()\n",
      "Accuracy 0.5573072242504702\n",
      "Confusion Matrix\n",
      " [[5154 3884]\n",
      " [4119 4921]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.56      9038\n",
      "           1       0.56      0.54      0.55      9040\n",
      "\n",
      "    accuracy                           0.56     18078\n",
      "   macro avg       0.56      0.56      0.56     18078\n",
      "weighted avg       0.56      0.56      0.56     18078\n",
      "\n",
      "Model MLPClassifier()\n",
      "Accuracy 0.6076446509569643\n",
      "Confusion Matrix\n",
      " [[5801 3237]\n",
      " [3856 5184]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62      9038\n",
      "           1       0.62      0.57      0.59      9040\n",
      "\n",
      "    accuracy                           0.61     18078\n",
      "   macro avg       0.61      0.61      0.61     18078\n",
      "weighted avg       0.61      0.61      0.61     18078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = merged_df[[\"avg_temperature\", \"avg_dewpoint\", \"avg_relative_humidity\", \"avg_precipitation\", \"avg_snowfall\", \"avg_wind_direction\", \"avg_wind_speed\", \"avg_pressure\",\"day_sin\",\"day_cos\",\"holiday\",\"weekend\", \"day_after_rest\",\"hour_of_day\"]]\n",
    "y = merged_df[\"avg_delay_departure\"]\n",
    "\n",
    "median_y = y.median()\n",
    "\n",
    "new_y = y.apply(lambda x: 1 if x > median_y else 0)\n",
    "\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,new_y,test_size=0.2,random_state=42)\n",
    "\n",
    "models = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier(),BaggingClassifier(),GaussianNB(),SGDClassifier(),LogisticRegression(max_iter = 50000),RidgeClassifier(),SVC(),MLPClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    dummy_train(xtrain,xtest,ytrain,ytest,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's test now with 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds (deciles): [-8.52236667e+04  5.02787794e+01  6.84227309e+01  8.40487318e+01\n",
      "  9.96688172e+01  1.16149998e+02  1.34741261e+02  1.58619062e+02\n",
      "  1.92223096e+02  2.62006373e+02  3.31200000e+04]\n",
      "Model KNeighborsClassifier()\n",
      "Accuracy 0.1912822214846775\n",
      "Model DecisionTreeClassifier()\n",
      "Accuracy 0.25804845668768667\n",
      "Model RandomForestClassifier()\n",
      "Accuracy 0.34777077110299814\n",
      "Model AdaBoostClassifier()\n",
      "Accuracy 0.2285651067595973\n",
      "Model GradientBoostingClassifier()\n",
      "Accuracy 0.25373382011284434\n",
      "Model ExtraTreesClassifier()\n",
      "Accuracy 0.34030313087730946\n",
      "Model BaggingClassifier()\n",
      "Accuracy 0.30384998340524394\n",
      "Model GaussianNB()\n",
      "Accuracy 0.16113508131430468\n",
      "Model SGDClassifier()\n",
      "Accuracy 0.15853523619869456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leiya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogisticRegression()\n",
      "Accuracy 0.14570195818121473\n",
      "Model RidgeClassifier()\n",
      "Accuracy 0.16832614227237527\n",
      "Model SVC()\n",
      "Accuracy 0.13718331673857728\n",
      "Model MLPClassifier()\n",
      "Accuracy 0.13524726186525057\n"
     ]
    }
   ],
   "source": [
    "x = merged_df[[\"avg_temperature\", \"avg_dewpoint\", \"avg_relative_humidity\", \"avg_precipitation\", \"avg_snowfall\", \"avg_wind_direction\", \"avg_wind_speed\", \"avg_pressure\",\"day_sin\",\"day_cos\",\"holiday\",\"weekend\", \"day_after_rest\",\"hour_of_day\"]]\n",
    "y = merged_df[\"avg_delay_departure\"]\n",
    "\n",
    "thresholds = np.quantile(y, np.linspace(0, 1, 11))\n",
    "print(\"Thresholds (deciles):\", thresholds)\n",
    "\n",
    "y_binned = pd.cut(y, bins=thresholds, include_lowest=True, labels=range(10))\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y_binned,test_size=0.2,random_state=42)\n",
    "\n",
    "models = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier(),BaggingClassifier(),GaussianNB(),SGDClassifier(),LogisticRegression(max_iter=50000),RidgeClassifier(),SVC(),MLPClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    dummy_train(xtrain,xtest,ytrain,ytest,model , print_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 300 sec of delay of SNCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1 in y: 7.56%\n",
      "Model KNeighborsClassifier()\n",
      "Accuracy 0.9207323819006528\n",
      "Model DecisionTreeClassifier()\n",
      "Accuracy 0.9119924770439208\n",
      "Model RandomForestClassifier()\n",
      "Accuracy 0.9385994025887819\n",
      "Model AdaBoostClassifier()\n",
      "Accuracy 0.931463657484235\n",
      "Model GradientBoostingClassifier()\n",
      "Accuracy 0.9348932404026994\n",
      "Model ExtraTreesClassifier()\n",
      "Accuracy 0.9415864586790574\n",
      "Model BaggingClassifier()\n",
      "Accuracy 0.9338975550392743\n",
      "Model GaussianNB()\n",
      "Accuracy 0.7056643434008186\n",
      "Model SGDClassifier()\n",
      "Accuracy 0.9235534904303574\n",
      "Model LogisticRegression(max_iter=50000)\n",
      "Accuracy 0.9242172806726408\n",
      "Model RidgeClassifier()\n",
      "Accuracy 0.9242172806726408\n",
      "Model SVC()\n",
      "Accuracy 0.9242172806726408\n",
      "Model MLPClassifier()\n",
      "Accuracy 0.9242172806726408\n"
     ]
    }
   ],
   "source": [
    "x = merged_df[[\"avg_temperature\", \"avg_dewpoint\", \"avg_relative_humidity\", \"avg_precipitation\", \"avg_snowfall\", \"avg_wind_direction\", \"avg_wind_speed\", \"avg_pressure\",\"day_sin\",\"day_cos\",\"holiday\",\"weekend\", \"day_after_rest\",\"hour_of_day\"]]\n",
    "y = merged_df[\"avg_delay_departure\"]\n",
    "\n",
    "y = y.apply(lambda x: 1 if x > 300 else 0)\n",
    "\n",
    "print(f\"Percentage of 1 in y: {y.sum() / len(y) * 100:.2f}%\")\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "models = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier(),BaggingClassifier(),GaussianNB(),SGDClassifier(),LogisticRegression(max_iter=50000),RidgeClassifier(),SVC(),MLPClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    dummy_train(xtrain,xtest,ytrain,ytest,model , print_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 1 in y: 40.20%\n",
      "Model KNeighborsClassifier()\n",
      "Accuracy 0.6690452483681824\n",
      "Model DecisionTreeClassifier()\n",
      "Accuracy 0.7522402920677066\n",
      "Model RandomForestClassifier()\n",
      "Accuracy 0.8299037504148689\n",
      "Model AdaBoostClassifier()\n",
      "Accuracy 0.7359774311317624\n",
      "Model GradientBoostingClassifier()\n",
      "Accuracy 0.7523509237747539\n",
      "Model ExtraTreesClassifier()\n",
      "Accuracy 0.8322823321163846\n",
      "Model BaggingClassifier()\n",
      "Accuracy 0.8064498285208541\n",
      "Model GaussianNB()\n",
      "Accuracy 0.4663679610576391\n",
      "Model SGDClassifier()\n",
      "Accuracy 0.6365748423498174\n",
      "Model LogisticRegression(max_iter=50000)\n",
      "Accuracy 0.6352472618652506\n",
      "Model RidgeClassifier()\n",
      "Accuracy 0.6360216838145812\n",
      "Model SVC()\n",
      "Accuracy 0.6000663790242283\n",
      "Model MLPClassifier()\n",
      "Accuracy 0.7112512446067043\n"
     ]
    }
   ],
   "source": [
    "x = merged_df[[\"avg_temperature\", \"avg_dewpoint\", \"avg_relative_humidity\", \"avg_precipitation\", \"avg_snowfall\", \"avg_wind_direction\", \"avg_wind_speed\", \"avg_pressure\",\"day_sin\",\"day_cos\",\"holiday\",\"weekend\", \"day_after_rest\",\"hour_of_day\"]]\n",
    "y = merged_df[\"avg_delay_departure\"]\n",
    "\n",
    "y = y.apply(lambda x: 1 if x < 100 else 0)\n",
    "\n",
    "print(f\"Percentage of 1 in y: {y.sum() / len(y) * 100:.2f}%\")\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "models = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier(),ExtraTreesClassifier(),BaggingClassifier(),GaussianNB(),SGDClassifier(),LogisticRegression(max_iter=50000),RidgeClassifier(),SVC(),MLPClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    dummy_train(xtrain,xtest,ytrain,ytest,model , print_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
